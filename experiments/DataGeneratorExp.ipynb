{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42095e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current memory usage 7.4%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, SpatialDropout2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, f1_score, roc_auc_score, roc_curve\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import psutil\n",
    "print(f'current memory usage {psutil.virtual_memory().percent}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80fb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d24e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:02.187035Z",
     "iopub.status.busy": "2021-07-05T20:16:02.186644Z",
     "iopub.status.idle": "2021-07-05T20:16:04.243884Z",
     "shell.execute_reply": "2021-07-05T20:16:04.242974Z",
     "shell.execute_reply.started": "2021-07-05T20:16:02.186998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting folder paths in training_set\n",
    "train_filepaths = []\n",
    "\n",
    "for path, subdirs, files in os.walk('/home/jupyter/RealCNN/dataset/training_set/'):\n",
    "    for name in files:\n",
    "        train_filepaths.append(os.path.join(path, name))\n",
    "\n",
    "# Mapping labels...\n",
    "labels_training = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], train_filepaths))\n",
    "\n",
    "# Training paths & labels\n",
    "train_filepaths = pd.Series(train_filepaths, name = 'File').astype(str)\n",
    "train_labels = pd.Series(labels_training, name='Label')\n",
    "\n",
    "# Concatenating...\n",
    "trainset_df = pd.concat([train_filepaths, train_labels], axis=1)\n",
    "trainset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5738d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:04.246121Z",
     "iopub.status.busy": "2021-07-05T20:16:04.245726Z",
     "iopub.status.idle": "2021-07-05T20:16:04.283979Z",
     "shell.execute_reply": "2021-07-05T20:16:04.283155Z",
     "shell.execute_reply.started": "2021-07-05T20:16:04.246084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting folder paths in test_set\n",
    "test_filepaths = []\n",
    "\n",
    "for path, subdirs, files in os.walk('/home/jupyter/RealCNN/dataset/test_set/'):\n",
    "    for name in files:\n",
    "        test_filepaths.append(os.path.join(path, name))\n",
    "\n",
    "# Mapping labels...\n",
    "labels_test = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], test_filepaths))\n",
    "\n",
    "# Test paths & labels\n",
    "test_filepaths = pd.Series(test_filepaths, name = 'File').astype(str)\n",
    "test_labels = pd.Series(labels_test, name='Label')\n",
    "\n",
    "# Concatenating...\n",
    "testset_df = pd.concat([test_filepaths, test_labels], axis=1)\n",
    "\n",
    "testset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55013f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:04.287609Z",
     "iopub.status.busy": "2021-07-05T20:16:04.287343Z",
     "iopub.status.idle": "2021-07-05T20:16:04.307445Z",
     "shell.execute_reply": "2021-07-05T20:16:04.306461Z",
     "shell.execute_reply.started": "2021-07-05T20:16:04.287584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Viewing data in both datasets\n",
    "print('Training Dataset:')\n",
    "\n",
    "print(f'Number of images in the training dataset: {trainset_df.shape[0]}')\n",
    "\n",
    "print(f'Number of images with cats: {trainset_df[\"Label\"].value_counts()[0]}')\n",
    "print(f'Number of images with dogs: {trainset_df[\"Label\"].value_counts()[1]}\\n')\n",
    "      \n",
    "print('Test Dataset:')\n",
    "      \n",
    "print(f'Number of images in the test dataset: {testset_df.shape[0]}')\n",
    "\n",
    "print(f'Number of images with cats: {testset_df[\"Label\"].value_counts()[0]}')\n",
    "print(f'Number of images with dogs: {testset_df[\"Label\"].value_counts()[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (96, 96, 3)\n",
    "batch_size = 128\n",
    "num_batches_per_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f4fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:04.583014Z",
     "iopub.status.busy": "2021-07-05T20:16:04.582629Z",
     "iopub.status.idle": "2021-07-05T20:16:04.607112Z",
     "shell.execute_reply": "2021-07-05T20:16:04.606219Z",
     "shell.execute_reply.started": "2021-07-05T20:16:04.582976Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "trainset_df = trainset_df.sample(frac = 1, random_state = 56).reset_index(drop = True).head(num_batches_per_epoch*batch_size)\n",
    "testset_df = testset_df.sample(frac = 1, random_state = 56).reset_index(drop = True)\n",
    "\n",
    "display(trainset_df.head())\n",
    "\n",
    "testset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1109c7",
   "metadata": {},
   "source": [
    "## 4. Generating batches of images\n",
    "In this part we will generate batches of images increasing the training data, for the test database we will just normalize the data using [ImageDataGenerator](https://keras.io/api/preprocessing/image/#imagedatagenerator-class)\n",
    "\n",
    "Parameters of ``ImageDataGenerator``:\n",
    "\n",
    "    rescale - Transform image size (normalization of data)\n",
    "    shear_range - Random geometric transformations\n",
    "    zoom_range - Images that will be zoomed\n",
    "    rotation_range - Degree of image rotation\n",
    "    width_shift_range - Image Width Change Range\n",
    "    height_shift_range - Image height change range\n",
    "    horizontal_flip - Rotate images horizontally\n",
    "    vertical_flip - Rotate images vertically\n",
    "    validation_split - Images that have been reserved for validation (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabdd15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:09.530993Z",
     "iopub.status.busy": "2021-07-05T20:16:09.530425Z",
     "iopub.status.idle": "2021-07-05T20:16:09.537715Z",
     "shell.execute_reply": "2021-07-05T20:16:09.53663Z",
     "shell.execute_reply.started": "2021-07-05T20:16:09.530953Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    rotation_range = 20,\n",
    "                                    width_shift_range = 0.1,\n",
    "                                    height_shift_range = 0.1,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip = True,\n",
    "                                    validation_split = 0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577a38a",
   "metadata": {},
   "source": [
    "## 5. Directory of training, validation and test images\n",
    "\n",
    "Here we make the division of the image bases for training, validation and testing of the model, for that we use the [flow_from_dataframe](https://keras.io/api/preprocessing/image/#flowfromdataframe-method)\n",
    "\n",
    "Parameters of ``flow_from_directory``:\n",
    "\n",
    "    dataframe - Dataframe containing the images directory\n",
    "    x_col - Column name containing the images directory\n",
    "    y_col - Name of the column containing what we want to predict\n",
    "    target_size - size of the images (remembering that it must be the same size as the input layer)\n",
    "    color_mode - RGB color standard\n",
    "    class_mode - binary class mode (cat/dog)\n",
    "    batch_size - batch size (32)\n",
    "    shuffle - Shuffle the data\n",
    "    seed - optional random seed for the shuffle\n",
    "    subset - Subset of data being training and validation (only used if using validation_split in ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818683e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:09.539906Z",
     "iopub.status.busy": "2021-07-05T20:16:09.539383Z",
     "iopub.status.idle": "2021-07-05T20:16:11.066955Z",
     "shell.execute_reply": "2021-07-05T20:16:11.065983Z",
     "shell.execute_reply.started": "2021-07-05T20:16:09.539864Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Preparing the training dataset ...\")\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe = trainset_df,\n",
    "    x_col = \"File\",\n",
    "    y_col = \"Label\",\n",
    "    target_size = target_size[:-1],\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = 2,\n",
    "    subset = \"training\")\n",
    "\n",
    "print(\"Preparing the validation dataset ...\")\n",
    "validation_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe = trainset_df,\n",
    "    x_col = \"File\",\n",
    "    y_col = \"Label\",\n",
    "    target_size = target_size[:-1],\n",
    "    color_mode =\"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = 2,\n",
    "    subset = \"validation\")\n",
    "\n",
    "print(\"Preparing the test dataset ...\")\n",
    "test_set = test_datagen.flow_from_dataframe(\n",
    "    dataframe = testset_df,\n",
    "    x_col = \"File\",\n",
    "    y_col = \"Label\",\n",
    "    target_size = target_size[:-1],\n",
    "    color_mode =\"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "print('Data generators are ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_generator(gen, nb_sample):\n",
    "    from tqdm import tqdm\n",
    "    cur_x, cur_y = next(gen)\n",
    "    input_shape = list(cur_x.shape)[1:]\n",
    "    batch_size = len(cur_x)\n",
    "\n",
    "    X_sample = np.zeros([nb_sample] + list(input_shape))\n",
    "    Y_sample = np.zeros((nb_sample,))\n",
    "    \n",
    "    \n",
    "    X_sample[0:0 + batch_size] = cur_x\n",
    "    Y_sample[0:0 + batch_size] = cur_y\n",
    "\n",
    "    for i in tqdm(range(batch_size, nb_sample, batch_size)):\n",
    "        cur_x, cur_y = next(gen)\n",
    "        if len(X_sample[i:i + batch_size]) < len(cur_x):\n",
    "            cur_x = cur_x[:len(X_sample[i:i + batch_size])]\n",
    "            cur_y = cur_y[:len(Y_sample[i:i + batch_size])]\n",
    "        if len(X_sample[i:i + batch_size]) >= len(cur_x):\n",
    "            shape = cur_x.shape[0]\n",
    "            X_sample[i:i + shape] = cur_x\n",
    "            Y_sample[i:i + shape] = cur_y\n",
    "    return X_sample, Y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, Y_sample = sample_from_generator(training_set, batch_size*num_batches_per_epoch)\n",
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e06ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Preparing the training dataset ...\")\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe = trainset_df,\n",
    "    x_col = \"File\",\n",
    "    y_col = \"Label\",\n",
    "    target_size = target_size[:-1],\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = 2,\n",
    "    subset = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alex_model(compile_model=False):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, SpatialDropout2D\n",
    "    #Instantiation\n",
    "    AlexNet = Sequential()\n",
    "\n",
    "    #1st Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=96, input_shape=target_size, kernel_size=(11,11), strides=(4,4), padding='same', activation='relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #2nd Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same', activation='relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #3rd Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "    #4th Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "    #5th Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #Passing it to a Fully Connected layer\n",
    "    AlexNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    AlexNet.add(Dense(4096, input_shape=(32,32,3,), activation='relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #2nd Fully Connected Layer\n",
    "    AlexNet.add(Dense(4096, activation='relu'))\n",
    "    #Add Dropout\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #3rd Fully Connected Layer\n",
    "    AlexNet.add(Dense(1000, activation='relu'))\n",
    "    #Add Dropout\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #Output Layer\n",
    "    AlexNet.add(Dense(1, activation='softmax'))\n",
    "    \n",
    "    if compile_model:\n",
    "        AlexNet.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return AlexNet\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afcba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from model_trainingtime_prediction.model_level_utils_cnn import convert_cnn2d_data, TimeHistory\n",
    "\n",
    "time_callback_data = TimeHistory()\n",
    "time_callback_gen_data = TimeHistory()\n",
    "\n",
    "CNN_data = Alex_model(compile_model=True)\n",
    "CNN_gen_data = Alex_model(compile_model=True)\n",
    "\n",
    "# Train\n",
    "CNN_model = CNN_data.fit(X_sample,Y_sample, batch_size = batch_size, epochs = 3, callbacks = [time_callback_data], verbose=False)\n",
    "CNN_model = CNN_gen_data.fit(training_set, batch_size = batch_size, epochs = 3, callbacks = [time_callback_gen_data], verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767795ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_times = np.array(time_callback_data.batch_times) * 1000\n",
    "np.median(batch_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec37866",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_times = np.array(time_callback_gen_data.batch_times) * 1000\n",
    "np.median(batch_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_train_start = False\n",
    "truncate_from = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_call_back = time_callback_data \n",
    "#target_call_back = time_callback_gen_data\n",
    "\n",
    "target_call_back.relative_by_train_start()\n",
    "\n",
    "epoch_data = []\n",
    "for index,(start,end) in enumerate(target_call_back.epoch_times_detail[truncate_from:]):\n",
    "    epoch_data.append((f'epoch{index+1+truncate_from} start', start))\n",
    "    epoch_data.append((f'epoch{index+1+truncate_from} end', end))\n",
    "batch_data = []\n",
    "for index,(start,end) in enumerate(target_call_back.batch_times_detail[truncate_from*num_batches_per_epoch:]):\n",
    "    batch_data.append((f'batch{index+1+truncate_from*num_batches_per_epoch} start', start))\n",
    "    batch_data.append((f'batch{index+1+truncate_from*num_batches_per_epoch} end', end))\n",
    "time_data = []\n",
    "time_data.extend(epoch_data)\n",
    "time_data.extend(batch_data)\n",
    "if mark_train_start:\n",
    "    time_data.append(('train start', 0))\n",
    "time_data.append(('train end', target_call_back.train_end_time))\n",
    "time_data = sorted(time_data, key=lambda x: x[1])\n",
    "\n",
    "names = [i for (i,j) in time_data]\n",
    "timestamp = [j for (i,j) in time_data]\n",
    "# Choose some nice levels\n",
    "levels = np.tile([-5, 5, -3, 3, -1, 1],\n",
    "                 int(np.ceil(len(timestamp)/6)))[:len(timestamp)]\n",
    "\n",
    "# Create figure and plot a stem plot with the date\n",
    "fig, ax = plt.subplots(figsize=(25, 8), constrained_layout=True)\n",
    "# ax.set(title=\"Model train timeline\")\n",
    "\n",
    "ax.vlines(timestamp, 0, levels, color=\"tab:red\")  # The vertical stems.\n",
    "ax.plot(timestamp, np.zeros_like(timestamp), \"-o\",\n",
    "        color=\"k\", markerfacecolor=\"w\")  # Baseline and markers on it.\n",
    "\n",
    "# annotate lines\n",
    "for d, l, r in zip(timestamp, levels, names):\n",
    "    ax.annotate(r, xy=(d, l),\n",
    "                xytext=(-3, np.sign(l)*3), textcoords=\"offset points\",\n",
    "                horizontalalignment=\"right\",\n",
    "                verticalalignment=\"bottom\" if l > 0 else \"top\", rotation=90, fontsize=20 if r.startswith('b') else 30)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "\n",
    "# remove y axis and spines\n",
    "ax.get_yaxis().set_visible(False)\n",
    "for spine in [\"left\", \"top\", \"right\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "ax.margins(y=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0264cf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#target_call_back = time_callback_data \n",
    "target_call_back = time_callback_gen_data\n",
    "\n",
    "target_call_back.relative_by_train_start()\n",
    "\n",
    "epoch_data = []\n",
    "for index,(start,end) in enumerate(target_call_back.epoch_times_detail[truncate_from:]):\n",
    "    epoch_data.append((f'epoch{index+1+truncate_from} start', start))\n",
    "    epoch_data.append((f'epoch{index+1+truncate_from} end', end))\n",
    "batch_data = []\n",
    "for index,(start,end) in enumerate(target_call_back.batch_times_detail[truncate_from*num_batches_per_epoch:]):\n",
    "    batch_data.append((f'batch{index+1+truncate_from*num_batches_per_epoch} start', start))\n",
    "    batch_data.append((f'batch{index+1+truncate_from*num_batches_per_epoch} end', end))\n",
    "time_data = []\n",
    "time_data.extend(epoch_data)\n",
    "time_data.extend(batch_data)\n",
    "if mark_train_start:\n",
    "    time_data.append(('train start', 0))\n",
    "time_data.append(('train end', target_call_back.train_end_time))\n",
    "time_data = sorted(time_data, key=lambda x: x[1])\n",
    "\n",
    "names = [i for (i,j) in time_data]\n",
    "timestamp = [j for (i,j) in time_data]\n",
    "# Choose some nice levels\n",
    "levels = np.tile([-5, 5, -3, 3, -1, 1],\n",
    "                 int(np.ceil(len(timestamp)/6)))[:len(timestamp)]\n",
    "\n",
    "# Create figure and plot a stem plot with the date\n",
    "fig, ax = plt.subplots(figsize=(25, 8), constrained_layout=True)\n",
    "# ax.set(title=\"Model train timeline\")\n",
    "\n",
    "ax.vlines(timestamp, 0, levels, color=\"tab:red\")  # The vertical stems.\n",
    "ax.plot(timestamp, np.zeros_like(timestamp), \"-o\",\n",
    "        color=\"k\", markerfacecolor=\"w\")  # Baseline and markers on it.\n",
    "\n",
    "# annotate lines\n",
    "for d, l, r in zip(timestamp, levels, names):\n",
    "    ax.annotate(r, xy=(d, l),\n",
    "                xytext=(-3, np.sign(l)*3), textcoords=\"offset points\",\n",
    "                horizontalalignment=\"right\",\n",
    "                verticalalignment=\"bottom\" if l > 0 else \"top\", rotation=90, fontsize=20 if r.startswith('b') else 30)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "\n",
    "# remove y axis and spines\n",
    "ax.get_yaxis().set_visible(False)\n",
    "for spine in [\"left\", \"top\", \"right\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "ax.margins(y=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3d4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3467312e",
   "metadata": {},
   "source": [
    "# if data gen is parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987cdfa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:02.187035Z",
     "iopub.status.busy": "2021-07-05T20:16:02.186644Z",
     "iopub.status.idle": "2021-07-05T20:16:04.243884Z",
     "shell.execute_reply": "2021-07-05T20:16:04.242974Z",
     "shell.execute_reply.started": "2021-07-05T20:16:02.186998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting folder paths in training_set\n",
    "train_filepaths = []\n",
    "\n",
    "for path, subdirs, files in os.walk('/home/jupyter/RealCNN/dataset/training_set/'):\n",
    "    for name in files:\n",
    "        train_filepaths.append(os.path.join(path, name))\n",
    "\n",
    "# Mapping labels...\n",
    "labels_training = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], train_filepaths))\n",
    "\n",
    "# Training paths & labels\n",
    "train_filepaths = pd.Series(train_filepaths, name = 'File').astype(str)\n",
    "train_labels = pd.Series(labels_training, name='Label')\n",
    "\n",
    "# Concatenating...\n",
    "trainset_df = pd.concat([train_filepaths, train_labels], axis=1)\n",
    "trainset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67acc36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:04.246121Z",
     "iopub.status.busy": "2021-07-05T20:16:04.245726Z",
     "iopub.status.idle": "2021-07-05T20:16:04.283979Z",
     "shell.execute_reply": "2021-07-05T20:16:04.283155Z",
     "shell.execute_reply.started": "2021-07-05T20:16:04.246084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting folder paths in test_set\n",
    "test_filepaths = []\n",
    "\n",
    "for path, subdirs, files in os.walk('/home/jupyter/RealCNN/dataset/test_set/'):\n",
    "    for name in files:\n",
    "        test_filepaths.append(os.path.join(path, name))\n",
    "\n",
    "# Mapping labels...\n",
    "labels_test = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], test_filepaths))\n",
    "\n",
    "# Test paths & labels\n",
    "test_filepaths = pd.Series(test_filepaths, name = 'File').astype(str)\n",
    "test_labels = pd.Series(labels_test, name='Label')\n",
    "\n",
    "# Concatenating...\n",
    "testset_df = pd.concat([test_filepaths, test_labels], axis=1)\n",
    "\n",
    "testset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac2cd47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:04.287609Z",
     "iopub.status.busy": "2021-07-05T20:16:04.287343Z",
     "iopub.status.idle": "2021-07-05T20:16:04.307445Z",
     "shell.execute_reply": "2021-07-05T20:16:04.306461Z",
     "shell.execute_reply.started": "2021-07-05T20:16:04.287584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "Number of images in the training dataset: 8000\n",
      "Number of images with cats: 4000\n",
      "Number of images with dogs: 4000\n",
      "\n",
      "Test Dataset:\n",
      "Number of images in the test dataset: 2000\n",
      "Number of images with cats: 1000\n",
      "Number of images with dogs: 1000\n"
     ]
    }
   ],
   "source": [
    "# Viewing data in both datasets\n",
    "print('Training Dataset:')\n",
    "\n",
    "print(f'Number of images in the training dataset: {trainset_df.shape[0]}')\n",
    "\n",
    "print(f'Number of images with cats: {trainset_df[\"Label\"].value_counts()[0]}')\n",
    "print(f'Number of images with dogs: {trainset_df[\"Label\"].value_counts()[1]}\\n')\n",
    "      \n",
    "print('Test Dataset:')\n",
    "      \n",
    "print(f'Number of images in the test dataset: {testset_df.shape[0]}')\n",
    "\n",
    "print(f'Number of images with cats: {testset_df[\"Label\"].value_counts()[0]}')\n",
    "print(f'Number of images with dogs: {testset_df[\"Label\"].value_counts()[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be452b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128, 128, 3)\n",
    "batch_size = 128\n",
    "num_batches_per_epoch = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c0cbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:04.583014Z",
     "iopub.status.busy": "2021-07-05T20:16:04.582629Z",
     "iopub.status.idle": "2021-07-05T20:16:04.607112Z",
     "shell.execute_reply": "2021-07-05T20:16:04.606219Z",
     "shell.execute_reply.started": "2021-07-05T20:16:04.582976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File Label\n",
       "0  /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "1  /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "2  /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "3  /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "4  /home/jupyter/RealCNN/dataset/training_set/cat...  cats"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/test_set/cats/ca...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/test_set/cats/ca...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/test_set/cats/ca...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/test_set/dogs/do...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/test_set/dogs/do...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                File Label\n",
       "0  /home/jupyter/RealCNN/dataset/test_set/cats/ca...  cats\n",
       "1  /home/jupyter/RealCNN/dataset/test_set/cats/ca...  cats\n",
       "2  /home/jupyter/RealCNN/dataset/test_set/cats/ca...  cats\n",
       "3  /home/jupyter/RealCNN/dataset/test_set/dogs/do...  dogs\n",
       "4  /home/jupyter/RealCNN/dataset/test_set/dogs/do...  dogs"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "trainset_df = trainset_df.sample(frac = 1, random_state = 56).reset_index(drop = True).head(num_batches_per_epoch*batch_size)\n",
    "testset_df = testset_df.sample(frac = 1, random_state = 56).reset_index(drop = True)\n",
    "\n",
    "display(trainset_df.head())\n",
    "\n",
    "testset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797aea0a",
   "metadata": {},
   "source": [
    "## 4. Generating batches of images\n",
    "In this part we will generate batches of images increasing the training data, for the test database we will just normalize the data using [ImageDataGenerator](https://keras.io/api/preprocessing/image/#imagedatagenerator-class)\n",
    "\n",
    "Parameters of ``ImageDataGenerator``:\n",
    "\n",
    "    rescale - Transform image size (normalization of data)\n",
    "    shear_range - Random geometric transformations\n",
    "    zoom_range - Images that will be zoomed\n",
    "    rotation_range - Degree of image rotation\n",
    "    width_shift_range - Image Width Change Range\n",
    "    height_shift_range - Image height change range\n",
    "    horizontal_flip - Rotate images horizontally\n",
    "    vertical_flip - Rotate images vertically\n",
    "    validation_split - Images that have been reserved for validation (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85935417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:09.530993Z",
     "iopub.status.busy": "2021-07-05T20:16:09.530425Z",
     "iopub.status.idle": "2021-07-05T20:16:09.537715Z",
     "shell.execute_reply": "2021-07-05T20:16:09.53663Z",
     "shell.execute_reply.started": "2021-07-05T20:16:09.530953Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                    shear_range = 0.2,\n",
    "                                    zoom_range = 0.1,\n",
    "                                    rotation_range = 20,\n",
    "                                    width_shift_range = 0.1,\n",
    "                                    height_shift_range = 0.1,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip = True,\n",
    "                                    validation_split = 0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece87866",
   "metadata": {},
   "source": [
    "## 5. Directory of training, validation and test images\n",
    "\n",
    "Here we make the division of the image bases for training, validation and testing of the model, for that we use the [flow_from_dataframe](https://keras.io/api/preprocessing/image/#flowfromdataframe-method)\n",
    "\n",
    "Parameters of ``flow_from_directory``:\n",
    "\n",
    "    dataframe - Dataframe containing the images directory\n",
    "    x_col - Column name containing the images directory\n",
    "    y_col - Name of the column containing what we want to predict\n",
    "    target_size - size of the images (remembering that it must be the same size as the input layer)\n",
    "    color_mode - RGB color standard\n",
    "    class_mode - binary class mode (cat/dog)\n",
    "    batch_size - batch size (32)\n",
    "    shuffle - Shuffle the data\n",
    "    seed - optional random seed for the shuffle\n",
    "    subset - Subset of data being training and validation (only used if using validation_split in ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82d506c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/cat...</td>\n",
       "      <td>cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7676</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7679</th>\n",
       "      <td>/home/jupyter/RealCNN/dataset/training_set/dog...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7680 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   File Label\n",
       "0     /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "1     /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "2     /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "3     /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "4     /home/jupyter/RealCNN/dataset/training_set/cat...  cats\n",
       "...                                                 ...   ...\n",
       "7675  /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "7676  /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "7677  /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "7678  /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "7679  /home/jupyter/RealCNN/dataset/training_set/dog...  dogs\n",
       "\n",
       "[7680 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7702644b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T20:16:09.539906Z",
     "iopub.status.busy": "2021-07-05T20:16:09.539383Z",
     "iopub.status.idle": "2021-07-05T20:16:11.066955Z",
     "shell.execute_reply": "2021-07-05T20:16:11.065983Z",
     "shell.execute_reply.started": "2021-07-05T20:16:09.539864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the training dataset ...\n",
      "Found 6912 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Preparing the training dataset ...\")\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe = trainset_df,\n",
    "    x_col = \"File\",\n",
    "    y_col = \"Label\",\n",
    "    target_size = target_size[:-1],\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = 2,\n",
    "    subset = \"training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d4a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_generator(gen, nb_sample):\n",
    "    from tqdm import tqdm\n",
    "    cur_x, cur_y = next(gen)\n",
    "    input_shape = list(cur_x.shape)[1:]\n",
    "    batch_size = len(cur_x)\n",
    "\n",
    "    X_sample = np.zeros([nb_sample] + list(input_shape))\n",
    "    Y_sample = np.zeros((nb_sample,))\n",
    "    \n",
    "    \n",
    "    X_sample[0:0 + batch_size] = cur_x\n",
    "    Y_sample[0:0 + batch_size] = cur_y\n",
    "\n",
    "    for i in tqdm(range(batch_size, nb_sample, batch_size)):\n",
    "        cur_x, cur_y = next(gen)\n",
    "        if len(X_sample[i:i + batch_size]) < len(cur_x):\n",
    "            cur_x = cur_x[:len(X_sample[i:i + batch_size])]\n",
    "            cur_y = cur_y[:len(Y_sample[i:i + batch_size])]\n",
    "        if len(X_sample[i:i + batch_size]) >= len(cur_x):\n",
    "            shape = cur_x.shape[0]\n",
    "            X_sample[i:i + shape] = cur_x\n",
    "            Y_sample[i:i + shape] = cur_y\n",
    "    return X_sample, Y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cfa7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:33<00:00,  1.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7680, 128, 128, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample, Y_sample = sample_from_generator(training_set, batch_size*num_batches_per_epoch)\n",
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1421baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the training dataset ...\n",
      "Found 6912 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Preparing the training dataset ...\")\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe = trainset_df,\n",
    "    x_col = \"File\",\n",
    "    y_col = \"Label\",\n",
    "    target_size = target_size[:-1],\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = 2,\n",
    "    subset = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a774fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alex_model(compile_model=False):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, SpatialDropout2D\n",
    "    #Instantiation\n",
    "    AlexNet = Sequential()\n",
    "\n",
    "    #1st Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=96, input_shape=target_size, kernel_size=(11,11), strides=(4,4), padding='same', activation='relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #2nd Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same', activation='relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #3rd Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "    #4th Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "\n",
    "    #5th Convolutional Layer\n",
    "    AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "    #Passing it to a Fully Connected layer\n",
    "    AlexNet.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    AlexNet.add(Dense(4096, input_shape=(32,32,3,), activation='relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #2nd Fully Connected Layer\n",
    "    AlexNet.add(Dense(4096, activation='relu'))\n",
    "    #Add Dropout\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #3rd Fully Connected Layer\n",
    "    AlexNet.add(Dense(1000, activation='relu'))\n",
    "    #Add Dropout\n",
    "    AlexNet.add(Dropout(0.4))\n",
    "\n",
    "    #Output Layer\n",
    "    AlexNet.add(Dense(1, activation='softmax'))\n",
    "    \n",
    "    if compile_model:\n",
    "        AlexNet.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return AlexNet\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2a368cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current memory usage 93.1%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print(f'current memory usage {psutil.virtual_memory().percent}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dadfbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use some memory\n",
    "x = np.ones((1000, 1000, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cf573fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ones((1000, 1000, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d679b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.ones((1000, 1000, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.ones((1000, 1000, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from model_trainingtime_prediction.model_level_utils_cnn import convert_cnn2d_data, TimeHistory\n",
    "\n",
    "time_callback_data = TimeHistory()\n",
    "time_callback_gen_data = TimeHistory()\n",
    "\n",
    "CNN_data = Alex_model(compile_model=True)\n",
    "CNN_gen_data = Alex_model(compile_model=True)\n",
    "\n",
    "# Train\n",
    "CNN_model = CNN_data.fit(X_sample,Y_sample, batch_size = batch_size, epochs = 50, callbacks = [time_callback_data], verbose=False)\n",
    "# CNN_model = CNN_gen_data.fit(training_set, batch_size = batch_size, epochs = 3, callbacks = [time_callback_gen_data], verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_times = np.array(time_callback_data.batch_times) * 1000\n",
    "np.median(batch_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fe6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_times = np.array(time_callback_gen_data.batch_times) * 1000\n",
    "np.median(batch_times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d73210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
