{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaldhXAoJ4TQ"
   },
   "source": [
    "https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vloAjkOAlTDK",
    "outputId": "d49e9959-1c8e-4aa9-d6ce-5239fc8919c8"
   },
   "outputs": [],
   "source": [
    "!pip install -i https://test.pypi.org/simple/ xin-util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhdueSwhmBcj",
    "outputId": "79ebd530-c3b6-4288-f2ab-536207866e81"
   },
   "outputs": [],
   "source": [
    "from model_trainingtime_prediction.env_detect import gpu_features\n",
    "gpu_features().get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPicAmE-EP3G"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "print(f'current memory usage {psutil.virtual_memory().percent}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for valid\n",
    "def valid_padding_output(input_size, kernel_size, stride):\n",
    "  pos = kernel_size\n",
    "  output = 1\n",
    "  while True:\n",
    "    pos += stride\n",
    "    output += 1\n",
    "    if pos+stride > input_size:\n",
    "      break\n",
    "  padding = -(input_size - pos)\n",
    "  return output\n",
    "\n",
    "# for same\n",
    "def same_padding_output(input_size, kernel_size, stride):\n",
    "  if stride == 1:\n",
    "    return input_size\n",
    "  else:\n",
    "    pos = 1\n",
    "    output = 1\n",
    "    while True:\n",
    "      pos += stride\n",
    "      output += 1\n",
    "      if pos+stride > input_size:\n",
    "        break\n",
    "    padding = pos+kernel_size-1 - input_size\n",
    "    return output\n",
    "\n",
    "def get_data_shape_flow_keras(input_shape, conv_model_obj, start_from=1, up_to=3, conv_weight=1, pool_weight=1):\n",
    "  multiplications = []\n",
    "  shape_flow = []\n",
    "  dense_shapes = []\n",
    "  input_shape = conv_weight*np.array(input_shape[start_from:up_to])\n",
    "  shape_flow.append(input_shape)\n",
    "  conv_shape_flow = []\n",
    "  polling_shape_flow = []\n",
    "  conv_shape_flow.append(input_shape)\n",
    "  for idx, layer_data in enumerate(conv_model_obj.get_config()['layers']):\n",
    "    layer_name = layer_data['class_name']\n",
    "    layer_config = layer_data['config']\n",
    "    if layer_name=='Conv2D' or layer_name=='SeparableConv2D':\n",
    "      filters = layer_config['filters']\n",
    "      kernel_size = layer_config['kernel_size'][0]\n",
    "      strides = layer_config['strides'][0]\n",
    "      padding_method = layer_config['padding']\n",
    "      previous_channels = input_shape[-1]\n",
    "      if padding_method == 'same':\n",
    "        output = same_padding_output(input_shape[0], kernel_size, strides)\n",
    "        input_shape = [output, output, filters]\n",
    "        conv_shape_flow.append(conv_weight*np.array(input_shape[start_from:up_to]))\n",
    "        shape_flow.append(conv_weight*np.array(input_shape[start_from:up_to]))\n",
    "        muls = kernel_size * kernel_size * previous_channels * output * output\n",
    "        multiplications.append(muls)\n",
    "      else:\n",
    "        output = valid_padding_output(input_shape[0], kernel_size, strides)\n",
    "        input_shape = [output, output, filters]\n",
    "        conv_shape_flow.append(conv_weight*np.array(input_shape[start_from:up_to]))\n",
    "        shape_flow.append(conv_weight*np.array(input_shape[start_from:up_to]))\n",
    "        muls = kernel_size * kernel_size * previous_channels * output * output\n",
    "        multiplications.append(muls)\n",
    "    if layer_name=='MaxPooling2D' or layer_name=='AveragePooling2D':\n",
    "      kernel_size = layer_config['pool_size'][0]\n",
    "      strides = layer_config['strides'][0]\n",
    "      padding_method = layer_config['padding']\n",
    "      if padding_method == 'same':\n",
    "        output = same_padding_output(input_shape[0], kernel_size, strides)\n",
    "        input_shape = [output, output, input_shape[-1]]\n",
    "        polling_shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "        shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "      else:\n",
    "        output = valid_padding_output(input_shape[0], kernel_size, strides)\n",
    "        input_shape = [output, output, input_shape[-1]]\n",
    "        polling_shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "        shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "    if layer_name=='ZeroPadding2D':\n",
    "        w_padding_size = layer_config['padding'][0]\n",
    "        h_padding_size = layer_config['padding'][1]\n",
    "        input_shape = [input_shape[0]+np.sum(w_padding_size), input_shape[1]+np.sum(h_padding_size), input_shape[-1]]\n",
    "        polling_shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "        shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "    if layer_name=='Cropping2D':\n",
    "        w_cropping_size = layer_config['cropping'][0]\n",
    "        h_cropping_size = layer_config['cropping'][1]\n",
    "        input_shape = [input_shape[0]-np.sum(w_cropping_size), input_shape[1]-np.sum(h_cropping_size), input_shape[-1]]\n",
    "        polling_shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "        shape_flow.append(pool_weight*np.array(input_shape[start_from:up_to]))\n",
    "    \n",
    "    if layer_name=='Dense':\n",
    "      dense_shapes.append(layer_config['units'])\n",
    "  return shape_flow, conv_shape_flow, polling_shape_flow, dense_shapes, multiplications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb7UlM2SlR5s"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "def get_flops(model, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = 1\n",
    "\n",
    "    real_model = tf.function(model).get_concrete_function(tf.TensorSpec([batch_size] + model.inputs[0].shape[1:], model.inputs[0].dtype))\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph,\n",
    "                                            run_meta=run_meta, cmd='op', options=opts)\n",
    "    return flops.total_float_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xcpobPElR5u"
   },
   "outputs": [],
   "source": [
    "optimizers = [\"sgd\", \"rmsprop\", \"adam\", \"adadelta\", \"adagrad\", \"adamax\", \"nadam\", \"ftrl\"]\n",
    "losses = [\"mae\", \"mape\", \"mse\", \"msle\", \"poisson\", \"categorical_crossentropy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIXzRWYBlR5u"
   },
   "outputs": [],
   "source": [
    "input_shape = (75, 75, 3)\n",
    "classes = 10\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "truncate_from = 2\n",
    "trials = 2\n",
    "optimizer = 'rmsprop'\n",
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzaYHCahRKX1"
   },
   "outputs": [],
   "source": [
    "LeNet_5 = Sequential()\n",
    "\n",
    "LeNet_5.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "LeNet_5.add(AveragePooling2D())\n",
    "\n",
    "LeNet_5.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "LeNet_5.add(AveragePooling2D())\n",
    "\n",
    "LeNet_5.add(Flatten())\n",
    "\n",
    "LeNet_5.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "LeNet_5.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "LeNet_5.add(Dense(units=classes, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42dSEBETaBQT"
   },
   "outputs": [],
   "source": [
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(classes))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "#AlexNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWK9dtLOKqZF"
   },
   "outputs": [],
   "source": [
    "Xception = tf.keras.applications.Xception(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btahAtXrIpL7"
   },
   "outputs": [],
   "source": [
    "VGG16 = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02_rq-jcJmyh"
   },
   "outputs": [],
   "source": [
    "VGG19 = tf.keras.applications.VGG19(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKs3tv7DJ00K"
   },
   "outputs": [],
   "source": [
    "ResNet50 = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJ1Ht8x8KGIj"
   },
   "outputs": [],
   "source": [
    "ResNet101 = tf.keras.applications.ResNet101(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TaU2m43KYX_"
   },
   "outputs": [],
   "source": [
    "ResNet152 = tf.keras.applications.ResNet152(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkXkS9VGK6es"
   },
   "outputs": [],
   "source": [
    "ResNet50V2 = tf.keras.applications.ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7cEVkNuLA3n"
   },
   "outputs": [],
   "source": [
    "ResNet101V2 = tf.keras.applications.ResNet101V2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCIOErLnLFWg"
   },
   "outputs": [],
   "source": [
    "ResNet152V2 = tf.keras.applications.ResNet152V2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeMJqUpMLJFy"
   },
   "outputs": [],
   "source": [
    "InceptionV3 = tf.keras.applications.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUW1A4nILQD2"
   },
   "outputs": [],
   "source": [
    "InceptionResNetV2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MJI_DmyLahy"
   },
   "outputs": [],
   "source": [
    "MobileNet = tf.keras.applications.MobileNet(\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a9Jzk3uLkde"
   },
   "outputs": [],
   "source": [
    "MobileNetV2 = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=None,\n",
    "    alpha=1.0,\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hco7-3b_LrdW"
   },
   "outputs": [],
   "source": [
    "DenseNet121 = tf.keras.applications.DenseNet121(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amyGD6--L_Ql"
   },
   "outputs": [],
   "source": [
    "DenseNet169 = tf.keras.applications.DenseNet169(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-h7RuoUMKcW"
   },
   "outputs": [],
   "source": [
    "DenseNet201 = tf.keras.applications.DenseNet201(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBIjQ17DMQzJ"
   },
   "outputs": [],
   "source": [
    "NASNetLarge = tf.keras.applications.NASNetLarge(\n",
    "    input_shape=input_shape,\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3_p75woMfv3"
   },
   "outputs": [],
   "source": [
    "NASNetMobile = tf.keras.applications.NASNetMobile(\n",
    "    input_shape=input_shape,\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYr6NDQKMnQu"
   },
   "outputs": [],
   "source": [
    "EfficientNetB0 = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrhVyXwnO3SN"
   },
   "outputs": [],
   "source": [
    "EfficientNetB1 = tf.keras.applications.EfficientNetB1(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2BKY5y-PHFy"
   },
   "outputs": [],
   "source": [
    "EfficientNetB2 = tf.keras.applications.EfficientNetB2(\n",
    "    include_top=True,\n",
    "    weights=None, \n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxx3tfHsPHIe"
   },
   "outputs": [],
   "source": [
    "EfficientNetB3 = tf.keras.applications.EfficientNetB3(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJWlgN_zPHKn"
   },
   "outputs": [],
   "source": [
    "EfficientNetB4 = tf.keras.applications.EfficientNetB4(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwNVhj3vPHMx"
   },
   "outputs": [],
   "source": [
    "EfficientNetB5 = tf.keras.applications.EfficientNetB5(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVWBvIHwPHQe"
   },
   "outputs": [],
   "source": [
    "EfficientNetB6 = tf.keras.applications.EfficientNetB6(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sj21vGruPHTH"
   },
   "outputs": [],
   "source": [
    "EfficientNetB7 = tf.keras.applications.EfficientNetB7(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=classes,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJIoliNelR58"
   },
   "outputs": [],
   "source": [
    "# model_list = [LeNet_5, AlexNet, Xception, VGG16, VGG19, ResNet50, ResNet101, ResNet152, ResNet50V2, ResNet101V2, \n",
    "#               ResNet152V2, InceptionV3, InceptionResNetV2, MobileNet, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, \n",
    "#               NASNetLarge, NASNetMobile, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, \n",
    "#               EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7]\n",
    "\n",
    "# model_list_name = ['LeNet_5', 'AlexNet', 'Xception', 'VGG16', 'VGG19', 'ResNet50', 'ResNet101', 'ResNet152', 'ResNet50V2', 'ResNet101V2', \n",
    "#               'ResNet152V2', 'InceptionV3', 'InceptionResNetV2', 'MobileNet', 'MobileNetV2', 'DenseNet121', 'DenseNet169', 'DenseNet201', \n",
    "#               'NASNetLarge', 'NASNetMobile', 'EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3', \n",
    "#               'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7']\n",
    "\n",
    "\n",
    "model_list = [LeNet_5, AlexNet, Xception, VGG16, VGG19, ResNet50, ResNet101, ResNet152, ResNet50V2, ResNet101V2, \n",
    "              ResNet152V2, InceptionV3, InceptionResNetV2, MobileNet, DenseNet121, DenseNet169, DenseNet201, \n",
    "              NASNetLarge, NASNetMobile, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, \n",
    "              EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7]\n",
    "\n",
    "model_list_name = ['LeNet_5', 'AlexNet', 'Xception', 'VGG16', 'VGG19', 'ResNet50', 'ResNet101', 'ResNet152', 'ResNet50V2', 'ResNet101V2', \n",
    "              'ResNet152V2', 'InceptionV3', 'InceptionResNetV2', 'MobileNet', 'DenseNet121', 'DenseNet169', 'DenseNet201', \n",
    "              'NASNetLarge', 'NASNetMobile', 'EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3', \n",
    "              'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6', 'EfficientNetB7']\n",
    "\n",
    "# compile \n",
    "for m in model_list:\n",
    "    m.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkSGu3IAlR58"
   },
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_start_time = time.time()\n",
    "        self.epoch_times = []\n",
    "        self.batch_times = []\n",
    "        self.epoch_times_detail = []\n",
    "        self.batch_times_detail = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        self.train_end_time = time.time()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        epoch_time_end = time.time()\n",
    "        self.epoch_times.append(epoch_time_end - self.epoch_time_start)\n",
    "        self.epoch_times_detail.append((self.epoch_time_start, epoch_time_end))\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs={}):\n",
    "        self.bacth_time_start = time.time()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs={}):\n",
    "        batch_time_end = time.time()\n",
    "        self.batch_times.append(batch_time_end - self.bacth_time_start)\n",
    "        self.batch_times_detail.append((self.bacth_time_start, batch_time_end))\n",
    "\n",
    "    def relative_by_train_start(self):\n",
    "        self.epoch_times_detail = np.array(self.epoch_times_detail) - self.train_start_time\n",
    "        self.batch_times_detail = np.array(self.batch_times_detail) - self.train_start_time\n",
    "        self.train_end_time = np.array(self.train_end_time) - self.train_start_time\n",
    "\n",
    "def find_last_dense_layer(keras_model):\n",
    "  configs = keras_model.get_config()['layers']\n",
    "  configs.reverse()\n",
    "  for layer_config in configs:\n",
    "    try:\n",
    "      if layer_config['class_name'] == 'Dense':\n",
    "        return layer_config['config']['units']\n",
    "      elif layer_config['class_name'] == 'Reshape':\n",
    "        return layer_config['config']['target_shape'][0]\n",
    "    except KeyError:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2amtaGKlR59"
   },
   "outputs": [],
   "source": [
    "times_data = []\n",
    "setup_data = []\n",
    "flops_data = []\n",
    "shape_data = []\n",
    "conv_shape_data = []\n",
    "multiplications_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jf-Zeus2lR59",
    "outputId": "0b856b34-a69e-471b-9467-e4b1df843ffe"
   },
   "outputs": [],
   "source": [
    "for idx, m in enumerate(tqdm(model_list)):  \n",
    "  batch_size_data_batch = []\n",
    "  batch_size_data_epoch = []\n",
    "  out_shape = find_last_dense_layer(m)\n",
    "  print(model_list_name[idx], out_shape)\n",
    "  x = np.ones((batch_size, *input_shape), dtype=np.float32)\n",
    "  y = np.ones((batch_size, out_shape), dtype=np.float32)\n",
    "  for _ in range(trials):\n",
    "    time_callback = TimeHistory()\n",
    "    m.fit(\n",
    "        x,\n",
    "        y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[time_callback],\n",
    "        verbose=False\n",
    "    )\n",
    "    times_batch = np.array(time_callback.batch_times) * 1000\n",
    "    times_epoch = np.array(time_callback.epoch_times) * 1000\n",
    "    batch_size_data_batch.extend(times_batch)\n",
    "    batch_size_data_epoch.extend(times_epoch)\n",
    "\n",
    "  batch_times_truncated = batch_size_data_batch[truncate_from:]\n",
    "  epoch_times_trancuted = batch_size_data_epoch[truncate_from:]\n",
    "  recovered_time = [\n",
    "      np.median(batch_times_truncated)\n",
    "  ] * truncate_from + batch_times_truncated\n",
    "  flops = get_flops(m, batch_size=1)\n",
    "  times_data.append(np.median(batch_times_truncated))\n",
    "  setup_data.append(np.sum(batch_size_data_batch) - sum(recovered_time))\n",
    "  flops_data.append(flops)\n",
    "  shape_flow, conv_shape_flow, polling_shape_flow, dense_shapes, multiplications = get_data_shape_flow_keras(input_shape, m)\n",
    "  shape_sum = np.sum([np.prod(i) for i in shape_flow])\n",
    "  shape_data.append(shape_sum)\n",
    "  conv_sum = np.sum([np.prod(i) for i in conv_shape_flow])\n",
    "  conv_shape_data.append(conv_sum)\n",
    "  multiplications_data.append(np.sum(multiplications))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# for idx, name in enumerate(model_list_name):\n",
    "#     if name.startswith('Eff'):\n",
    "#         pass\n",
    "#     else:\n",
    "#         plt.text(flops_data[idx], times_data[idx], name, size=15)\n",
    "#         plt.scatter(flops_data[idx], times_data[idx])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for idx, name in enumerate(model_list_name):\n",
    "    if name.startswith('Eff'):\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(conv_shape_data[idx], times_data[idx], name, size=15)\n",
    "        plt.scatter(conv_shape_data[idx], times_data[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for idx, name in enumerate(model_list_name):\n",
    "    if name.startswith('Eff'):\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(shape_data[idx], times_data[idx], name, size=15)\n",
    "        plt.scatter(shape_data[idx], times_data[idx])\n",
    "plt.show()\n",
    "plt.savefig('withouteff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, name in enumerate(model_list_name):\n",
    "    if name.startswith('Eff'):\n",
    "        pass\n",
    "    else:\n",
    "        plt.text(multiplications_data[idx], times_data[idx], name, size=15)\n",
    "        plt.scatter(multiplications_data[idx], times_data[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_layers = set()\n",
    "for layer in DenseNet121.get_config()['layers']:\n",
    "    unique_layers.add(layer['class_name'])\n",
    "unique_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2time = dict(zip(model_list_name, times_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2flop = dict([('VGG19', 19.6), ('VGG16', 15.3), ('ResNet152', 11.3), ('ResNet101', 7.6), ('ResNet50', 3.8), ('AlexNet', 0.72)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,flops in name2flop.items():\n",
    "    time = name2time[name]\n",
    "    plt.scatter(flops, time)\n",
    "    plt.text(flops, time, name, size=15)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_layers = set()\n",
    "# for layer in DenseNet121.get_config()['layers']:\n",
    "#     if layer['class_name']=='Concatenate':\n",
    "#         display(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model_list_name': model_list_name, 'times_data': times_data, 'setup_data': setup_data, 'flops_data': flops_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xin_util.ZipAndUnzip import zip_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.86it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 794.94it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 832.81it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 4000/4000 [00:04<00:00, 908.93it/s] \n",
      "100%|██████████| 4000/4000 [00:05<00:00, 702.55it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 888.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 353.74it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 838.95it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 4000/4000 [00:04<00:00, 927.34it/s] \n",
      "100%|██████████| 4000/4000 [00:04<00:00, 839.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.07it/s]\n"
     ]
    }
   ],
   "source": [
    "zip_file('RealCaseTesting', 'RealCaseTesting.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Conv.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
